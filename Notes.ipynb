{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acf744d8",
   "metadata": {},
   "source": [
    "## **Goal**\n",
    "\n",
    "**Understand Digital Video Processing**\n",
    "\n",
    "**Build a Video Player from Scratch Using `C++`**\n",
    "\n",
    "**Understand Concepts Related to Video Compression and Decompression**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d25209",
   "metadata": {},
   "source": [
    "## **Video Compression**\n",
    "\n",
    "**What is Compression?**\n",
    "\n",
    "Compression is the process of reducing the size of data by encoding it more efficiently. In the context of video, compression is essential to reduce the file size of video files, making them easier to store and transmit over networks.\n",
    "\n",
    "Say, any raw video file when the recording just happened, it is in uncompressed format. Such files are huge in size for example, a 1-minute uncompressed 1080p video can take up several gigabytes of storage space.\n",
    "\n",
    "As we've `Storage` and `Bandwidth` limitations, we need to compress these video files to make them manageable. Compression helps in reducing the file size while maintaining an acceptable level of quality.\n",
    "\n",
    "There are two main types of video compression:\n",
    "\n",
    "1. **Lossless Compression**: In lossless compression, the original data can be perfectly reconstructed from the compressed data. This type of compression is less common for video due to the high data rates involved, but it is used in scenarios where quality is paramount, such as medical imaging or archival footage.\n",
    "\n",
    "2. **Lossy Compression**: In lossy compression, some data is discarded to achieve higher compression ratios. This type of compression is more common for video, as it allows for significant reductions in file size while still maintaining acceptable visual quality. Examples of lossy compression algorithms include `H.264`, `H.265 (HEVC)`, and `VP9`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e4ec0",
   "metadata": {},
   "source": [
    "So we've `Encoders` and `Decoders` (Codecs) that are responsible for compressing and decompressing video data using various algorithms and techniques.\n",
    "\n",
    "**`Encoder`**: An encoder takes raw video data and applies compression algorithms to reduce its size. It analyzes the video frames, identifies redundancies, and encodes the data in a more efficient format.\n",
    "\n",
    "**`Decoder`**: A decoder takes the compressed video data and reconstructs it back into a format that can be displayed or played. It reverses the compression process applied by the encoder.\n",
    "\n",
    "### **Working of Video Compression (`Encoder`)**\n",
    "\n",
    "We know video is a sequence of images (frames) displayed in rapid succession to create the illusion of motion.\n",
    "\n",
    "So if in a raw video, suppose there are 30 frames per second (fps), and let's say for at any point of time, for `1 Second` we might a `30 Frames` which are almost similar to each other with very minor changes.\n",
    "\n",
    "If we can find a way to store only the differences between these frames rather than storing each frame in its entirety, we can significantly reduce the amount of data needed to represent the video.\n",
    "\n",
    "So this is the base concept of video compression, where we exploit the temporal redundancy between frames to reduce the overall data size.\n",
    "\n",
    "Similarly, there are other such areas where we can find `Redundancy` and `Exploit` them to achieve compression.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244af4c0",
   "metadata": {},
   "source": [
    "## **Step 1**\n",
    "\n",
    "### **Breaking into `Blocks`**\n",
    "\n",
    "Video frames are divided into smaller units called `blocks` or `macroblocks` (typically 16x16 pixels). This division allows the compression algorithm to analyze and process smaller sections of the frame independently.\n",
    "\n",
    "These `Blocks` will be processed `Sequentially` for compression.\n",
    "\n",
    "Or,\n",
    "\n",
    "Batch of `Slices` (each slice containing multiple blocks) can be processed together. This way we can take advantage of `Multi-threading` for faster processing.\n",
    "\n",
    "Or,\n",
    "\n",
    "Tiles i.e. larger rectangular regions of the frame can be processed independently. This approach is often used in parallel processing scenarios to improve encoding and decoding speed.\n",
    "\n",
    "<img src=\"./Notes_images/macroblocks.png\" alt=\"macroblocks\" width=\"500\"/>\n",
    "\n",
    "**Note:**\n",
    "\n",
    "The `Size` of these blocks can vary depending on the compression algorithm used. For example, some algorithms may use smaller blocks (e.g., 8x8 pixels) for more detailed analysis, while others may use larger blocks (e.g., 16x16 pixels) for faster processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ee55e",
   "metadata": {},
   "source": [
    "Cnt... Next Day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d02a65",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<hr>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7099b8a1",
   "metadata": {},
   "source": [
    "## **`Codec`**\n",
    "\n",
    "A `Codec` (Compressor-Decompressor) is a software or hardware component that is responsible for encoding (compressing) and decoding (decompressing) digital video and audio data. Codecs use various algorithms to reduce the size of multimedia files while maintaining an acceptable level of quality.\n",
    "\n",
    "**Main Goal of Codec:**\n",
    "\n",
    "- To reduce the file size of video and audio data for efficient storage and transmission.\n",
    "\n",
    "- To ensure that the compressed data can be accurately reconstructed during playback.\n",
    "\n",
    "- The `Quality` of the compressed video or audio should be acceptable to the end-user, balancing between file size and visual/auditory fidelity.\n",
    "\n",
    "### **Understanding `Bit Depth`**\n",
    "\n",
    "**Bit Depth** refers to the number of bits used to represent the color information of each pixel in a digital image or video. It determines the range of colors that can be represented and the level of detail in the color representation.\n",
    "\n",
    "- A higher bit depth allows for a greater number of colors and finer gradations between colors, resulting in more accurate and vibrant images. But it also increases the amount of data required to store the image or video.\n",
    "\n",
    "For example, if the `Bit Depth` is `8 bits`, it means that each pixel can represent `2^8 = 256` different colors or shades of gray. This is commonly used in standard images and videos.\n",
    "\n",
    "Since we've `3 Color Channels` (Red, Green, Blue) in an RGB image, the total number of colors that can be represented with an 8-bit depth is `256 x 256 x 256 = 16,777,216` colors.\n",
    "\n",
    "But if we used `12 bits` per channel, the total number of colors would be `2^12 x 2^12 x 2^12 = 68,719,476,736` colors, which is significantly higher and allows for more detailed color representation.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
